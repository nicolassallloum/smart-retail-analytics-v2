# ğŸ“Š Smart Retail Analytics

*End-to-End Data Engineering & Retail Analytics Project*

![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED?style=flat&logo=docker&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791?style=flat&logo=postgresql&logoColor=white)
![Python](https://img.shields.io/badge/Python-ETL-3776AB?style=flat&logo=python&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-Visualization-F2C811?style=flat&logo=powerbi&logoColor=black)

---

## ğŸš€ Project Overview

Smart Retail Analytics is a complete end-to-end data engineering project designed to simulate a real-world retail data warehouse architecture. This project reflects enterprise-grade retail analytics architecture suitable for production-scale systems.

The project demonstrates the following key capabilities:

- Data ingestion and transformation (ETL)
- Star schema data warehouse modeling
- PostgreSQL-based analytical storage
- Dockerized infrastructure
- Business Intelligence integration (Power BI)

---

## ğŸ— Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data (CSV / Generated)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Python ETL Pipeline       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL Data Warehouse       â”‚
â”‚      (Star Schema)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Power BI Desktop               â”‚
â”‚  (Analytics Layer)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ›  Tech Stack

| Layer            | Technology                             |
| ---------------- | -------------------------------------- |
| Containerization | Docker & Docker Compose                |
| Data Warehouse   | PostgreSQL 15                          |
| ETL              | Python (Pandas, Psycopg2 / SQLAlchemy) |
| Data Modeling    | Star Schema                            |
| BI Layer         | Power BI Desktop                       |
| Optional NoSQL   | MongoDB                                |

---

## ğŸ“‚ Project Structure

```
smart-retail-analytics/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ generate_raw_data.py
â”‚   â”œâ”€â”€ transform_data.py
â”‚   â””â”€â”€ load_to_postgres.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â””â”€â”€ indexes.sql
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_sales.csv
â”‚
â””â”€â”€ powerbi/
    â””â”€â”€ dashboard.pbix
```

---

## ğŸ§  Data Warehouse Design

The data warehouse follows a strict **Star Schema Model** to optimize for analytical queries.

### ğŸ“Œ Fact Table

**fact_sales**

- `order_id`
- `date_id`
- `customer_id`
- `product_id`
- `quantity`
- `gross_amount`
- `net_amount`
- `discount`
- `payment_method`
- `is_returned`

### ğŸ“Œ Dimension Tables

- **dim_customer**: Customer demographics and details
- **dim_product**: Product categorization and pricing
- **dim_date**: Date hierarchy for temporal analysis

---

## âš™ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/smart-retail-analytics.git
cd smart-retail-analytics
```

### 2ï¸âƒ£ Start Infrastructure

```bash
docker compose up -d
```

PostgreSQL will run on: `localhost:55432`

### 3ï¸âƒ£ Run ETL Pipeline

Set environment variable:

```bash
export DB_PASSWORD=sra_password
```

Run the loader script:

```bash
python etl/load_to_postgres.py
```

Expected output:

```
ğŸš€ Starting Load to Postgres...
ğŸ“¥ Inserting data...
âœ… Completed successfully
```

### 4ï¸âƒ£ Verify Data

```bash
psql -h localhost -p 55432 -U postgres -d smart_retail_dw
```

Example validation query:

```sql
SELECT COUNT(*) FROM fact_sales;
```

---

## ğŸ“Š Power BI Integration

To connect Power BI Desktop to the data warehouse:

1. Open **Power BI Desktop**
2. Click **Get Data** â†’ **PostgreSQL**
3. Use the following credentials:
   - **Server:** localhost
   - **Port:** 55432
   - **Database:** smart_retail_dw
   - **Username:** postgres
   - **Password:** sra_password

---

## ğŸ“ˆ Sample Dashboard Metrics

The project enables the creation of the following analytical views:

- ğŸ’° **Total Revenue KPI**
- ğŸ“¦ **Total Orders**
- ğŸ“ˆ **Revenue by Month**
- ğŸ· **Sales by Category**
- ğŸ’³ **Payment Method Distribution**
- ğŸ”¥ **Top 10 Products**
- ğŸ“ **Sales by City**

---

## ğŸ§ª ETL Process Overview

The ETL pipeline performs the following logical steps:

1. Data ingestion from CSV / generated dataset
2. Data cleansing and validation
3. Data transformation
4. Star schema mapping
5. Bulk insert into PostgreSQL

---

## ğŸ” Configuration

### Environment Variables

| Variable        | Description         |
| --------------- | ------------------- |
| `DB_PASSWORD` | PostgreSQL password |

### ğŸ“¦ Docker Services

| Service    | Port  |
| ---------- | ----- |
| PostgreSQL | 55432 |
| MongoDB    | 27017 |

---

## ğŸ¯ Project Objectives

- Demonstrate practical data engineering workflow
- Design analytical-ready schema
- Build BI-ready warehouse
- Simulate enterprise retail analytics architecture

---

## ğŸ“š Future Enhancements

- Add Apache Airflow for orchestration
- Implement Kafka streaming ingestion
- Add CDC with Debezium
- Deploy Superset for server-side BI
- Add ClickHouse for high-performance analytics
- Cloud deployment on AWS / GCP

---

## â­ Why This Project Matters

This project showcases real-world warehouse modeling, Dockerized infrastructure management, ETL pipeline engineering, and BI integration. It demonstrates end-to-end data lifecycle management.

It reflects skills relevant for the following roles:

- **Data Engineering**
- **Analytics Engineering**
- **Business Intelligence**
- **Data Architecture**

---

## ğŸ‘¨â€ğŸ’» Author

**Nicolas Salloum (Nix)**
*Data Engineer*

---

<div align="center">
  <sub>Â© 2026 Smart Retail Analytics. All rights reserved.</sub>
</div>
